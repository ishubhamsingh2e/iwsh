{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "NUM_CLASSES = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import keras_tuner as kt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = './model'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = pd.read_csv(\n",
    "    \"C:/Users/shubham/Documents/git/iwsh/machine_learning/data/number/number.csv\")\n",
    "data_frame.drop([\"uid\"], axis=1, inplace=True)\n",
    "\n",
    "for i in range(0, 21):\n",
    "    data_frame.drop([f\"z{i}\"], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14390, 44)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hand</th>\n",
       "      <th>x0</th>\n",
       "      <th>y0</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>x3</th>\n",
       "      <th>y3</th>\n",
       "      <th>x4</th>\n",
       "      <th>...</th>\n",
       "      <th>y16</th>\n",
       "      <th>x17</th>\n",
       "      <th>y17</th>\n",
       "      <th>x18</th>\n",
       "      <th>y18</th>\n",
       "      <th>x19</th>\n",
       "      <th>y19</th>\n",
       "      <th>x20</th>\n",
       "      <th>y20</th>\n",
       "      <th>gesture</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.198411</td>\n",
       "      <td>0.747025</td>\n",
       "      <td>0.235151</td>\n",
       "      <td>0.738667</td>\n",
       "      <td>0.268972</td>\n",
       "      <td>0.697697</td>\n",
       "      <td>0.268697</td>\n",
       "      <td>0.654425</td>\n",
       "      <td>0.253942</td>\n",
       "      <td>...</td>\n",
       "      <td>0.664134</td>\n",
       "      <td>0.147525</td>\n",
       "      <td>0.622553</td>\n",
       "      <td>0.166481</td>\n",
       "      <td>0.619918</td>\n",
       "      <td>0.177274</td>\n",
       "      <td>0.658618</td>\n",
       "      <td>0.176243</td>\n",
       "      <td>0.672592</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.193464</td>\n",
       "      <td>0.728339</td>\n",
       "      <td>0.234930</td>\n",
       "      <td>0.710548</td>\n",
       "      <td>0.268882</td>\n",
       "      <td>0.653667</td>\n",
       "      <td>0.280233</td>\n",
       "      <td>0.601220</td>\n",
       "      <td>0.262587</td>\n",
       "      <td>...</td>\n",
       "      <td>0.632698</td>\n",
       "      <td>0.152037</td>\n",
       "      <td>0.597635</td>\n",
       "      <td>0.170634</td>\n",
       "      <td>0.575411</td>\n",
       "      <td>0.180758</td>\n",
       "      <td>0.614971</td>\n",
       "      <td>0.179107</td>\n",
       "      <td>0.638144</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.201815</td>\n",
       "      <td>0.668465</td>\n",
       "      <td>0.249525</td>\n",
       "      <td>0.622076</td>\n",
       "      <td>0.285454</td>\n",
       "      <td>0.563580</td>\n",
       "      <td>0.302071</td>\n",
       "      <td>0.503236</td>\n",
       "      <td>0.287489</td>\n",
       "      <td>...</td>\n",
       "      <td>0.542387</td>\n",
       "      <td>0.171598</td>\n",
       "      <td>0.500202</td>\n",
       "      <td>0.207042</td>\n",
       "      <td>0.479684</td>\n",
       "      <td>0.213964</td>\n",
       "      <td>0.526689</td>\n",
       "      <td>0.198493</td>\n",
       "      <td>0.541396</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.206287</td>\n",
       "      <td>0.617647</td>\n",
       "      <td>0.253612</td>\n",
       "      <td>0.584835</td>\n",
       "      <td>0.287096</td>\n",
       "      <td>0.523315</td>\n",
       "      <td>0.305104</td>\n",
       "      <td>0.463736</td>\n",
       "      <td>0.292773</td>\n",
       "      <td>...</td>\n",
       "      <td>0.504872</td>\n",
       "      <td>0.178925</td>\n",
       "      <td>0.460736</td>\n",
       "      <td>0.217125</td>\n",
       "      <td>0.442216</td>\n",
       "      <td>0.221329</td>\n",
       "      <td>0.489974</td>\n",
       "      <td>0.204648</td>\n",
       "      <td>0.504209</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.204903</td>\n",
       "      <td>0.588751</td>\n",
       "      <td>0.250742</td>\n",
       "      <td>0.558584</td>\n",
       "      <td>0.286239</td>\n",
       "      <td>0.495493</td>\n",
       "      <td>0.306021</td>\n",
       "      <td>0.438340</td>\n",
       "      <td>0.289818</td>\n",
       "      <td>...</td>\n",
       "      <td>0.485219</td>\n",
       "      <td>0.171706</td>\n",
       "      <td>0.440263</td>\n",
       "      <td>0.205936</td>\n",
       "      <td>0.419783</td>\n",
       "      <td>0.213251</td>\n",
       "      <td>0.468543</td>\n",
       "      <td>0.200633</td>\n",
       "      <td>0.485689</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   hand        x0        y0        x1        y1        x2        y2        x3  \\\n",
       "0     1  0.198411  0.747025  0.235151  0.738667  0.268972  0.697697  0.268697   \n",
       "1     1  0.193464  0.728339  0.234930  0.710548  0.268882  0.653667  0.280233   \n",
       "2     1  0.201815  0.668465  0.249525  0.622076  0.285454  0.563580  0.302071   \n",
       "3     1  0.206287  0.617647  0.253612  0.584835  0.287096  0.523315  0.305104   \n",
       "4     1  0.204903  0.588751  0.250742  0.558584  0.286239  0.495493  0.306021   \n",
       "\n",
       "         y3        x4  ...       y16       x17       y17       x18       y18  \\\n",
       "0  0.654425  0.253942  ...  0.664134  0.147525  0.622553  0.166481  0.619918   \n",
       "1  0.601220  0.262587  ...  0.632698  0.152037  0.597635  0.170634  0.575411   \n",
       "2  0.503236  0.287489  ...  0.542387  0.171598  0.500202  0.207042  0.479684   \n",
       "3  0.463736  0.292773  ...  0.504872  0.178925  0.460736  0.217125  0.442216   \n",
       "4  0.438340  0.289818  ...  0.485219  0.171706  0.440263  0.205936  0.419783   \n",
       "\n",
       "        x19       y19       x20       y20  gesture  \n",
       "0  0.177274  0.658618  0.176243  0.672592        0  \n",
       "1  0.180758  0.614971  0.179107  0.638144        0  \n",
       "2  0.213964  0.526689  0.198493  0.541396        0  \n",
       "3  0.221329  0.489974  0.204648  0.504209        0  \n",
       "4  0.213251  0.468543  0.200633  0.485689        0  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data_frame.shape)\n",
    "data_frame.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = len(set(data_frame[\"gesture\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data_frame.drop([\"gesture\"], axis=1)\n",
    "value = data_frame[\"gesture\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.to_numpy()\n",
    "value = value.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#{0, 1, 5, 6, 7, 8}\n",
    "\n",
    "flag = 0\n",
    "\n",
    "for i in set(data_frame[\"gesture\"]):\n",
    "    value[value == i] = flag\n",
    "    flag += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.unique(value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, value, train_size=0.95, random_state=RANDOM_SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "def model_builder(hp):\n",
    "    with tf.device(\"/GPU:0\"):\n",
    "        model = keras.Sequential()\n",
    "        for i in range(hp.Int('num_layers', 2, 20)):\n",
    "            model.add(layers.Dense(units=hp.Int('units_' + str(i),\n",
    "                                                min_value=32,\n",
    "                                                max_value=512,\n",
    "                                                step=32),\n",
    "                                   activation='relu'))\n",
    "        model.add(layers.Dense(NUM_CLASSES, activation='softmax'))\n",
    "        model.compile(\n",
    "            optimizer=keras.optimizers.Adam(\n",
    "                hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])),\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy'])\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project number\\number\\oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from number\\number\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.RandomSearch(\n",
    "    model_builder,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=100,\n",
    "    executions_per_trial=3,\n",
    "    directory='number',\n",
    "    project_name='number'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 21\n",
      "num_layers (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 20, 'step': 1, 'sampling': None}\n",
      "units_0 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
      "units_1 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
      "learning_rate (Choice)\n",
      "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}\n",
      "units_2 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
      "units_3 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
      "units_4 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
      "units_5 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
      "units_6 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
      "units_7 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
      "units_8 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
      "units_9 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
      "units_10 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
      "units_11 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
      "units_12 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
      "units_13 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
      "units_14 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
      "units_15 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
      "units_16 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
      "units_17 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
      "units_18 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 57 Complete [00h 01m 20s]\n",
      "val_accuracy: 0.9481481512387594\n",
      "\n",
      "Best val_accuracy So Far: 0.9666666587193807\n",
      "Total elapsed time: 00h 11m 30s\n",
      "\n",
      "Search: Running Trial #58\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "15                |4                 |num_layers\n",
      "256               |320               |units_0\n",
      "224               |352               |units_1\n",
      "0.0001            |0.001             |learning_rate\n",
      "384               |448               |units_2\n",
      "64                |384               |units_3\n",
      "96                |320               |units_4\n",
      "384               |32                |units_5\n",
      "288               |288               |units_6\n",
      "352               |320               |units_7\n",
      "160               |32                |units_8\n",
      "352               |32                |units_9\n",
      "288               |352               |units_10\n",
      "480               |160               |units_11\n",
      "128               |64                |units_12\n",
      "512               |480               |units_13\n",
      "192               |64                |units_14\n",
      "352               |160               |units_15\n",
      "416               |64                |units_16\n",
      "160               |320               |units_17\n",
      "512               |480               |units_18\n",
      "\n",
      "Epoch 1/10\n",
      "  5/428 [..............................] - ETA: 6s - loss: 1.7915 - accuracy: 0.1813  WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0072s vs `on_train_batch_end` time: 0.0080s). Check your callbacks.\n",
      "428/428 [==============================] - 6s 12ms/step - loss: 1.5873 - accuracy: 0.3120 - val_loss: 1.2032 - val_accuracy: 0.5111\n",
      "Epoch 2/10\n",
      "428/428 [==============================] - 5s 11ms/step - loss: 0.8996 - accuracy: 0.6158 - val_loss: 0.6969 - val_accuracy: 0.7181\n",
      "Epoch 3/10\n",
      "428/428 [==============================] - 4s 10ms/step - loss: 0.6139 - accuracy: 0.7763 - val_loss: 0.7515 - val_accuracy: 0.6694\n",
      "Epoch 4/10\n",
      "428/428 [==============================] - 4s 10ms/step - loss: 0.4745 - accuracy: 0.8401 - val_loss: 0.4355 - val_accuracy: 0.8389\n",
      "Epoch 5/10\n",
      "428/428 [==============================] - 5s 11ms/step - loss: 0.3728 - accuracy: 0.8821 - val_loss: 0.3009 - val_accuracy: 0.9042\n",
      "Epoch 6/10\n",
      "428/428 [==============================] - 5s 11ms/step - loss: 0.3275 - accuracy: 0.8977 - val_loss: 0.2555 - val_accuracy: 0.9194\n",
      "Epoch 7/10\n",
      "378/428 [=========================>....] - ETA: 0s - loss: 0.2630 - accuracy: 0.9207"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\shubham\\Documents\\git\\iwsh\\machine_learning\\data\\number\\nn_number.ipynb Cell 16\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/shubham/Documents/git/iwsh/machine_learning/data/number/nn_number.ipynb#X32sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m tuner\u001b[39m.\u001b[39;49msearch(X_train, y_train,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/shubham/Documents/git/iwsh/machine_learning/data/number/nn_number.ipynb#X32sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m              epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/shubham/Documents/git/iwsh/machine_learning/data/number/nn_number.ipynb#X32sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m              validation_data\u001b[39m=\u001b[39;49m(X_test, y_test))\n",
      "File \u001b[1;32mc:\\Users\\shubham\\Documents\\git\\iwsh\\venv\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py:183\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[1;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m    182\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_trial_begin(trial)\n\u001b[1;32m--> 183\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_trial(trial, \u001b[39m*\u001b[39mfit_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs)\n\u001b[0;32m    184\u001b[0m \u001b[39m# `results` is None indicates user updated oracle in `run_trial()`.\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[39mif\u001b[39;00m results \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\shubham\\Documents\\git\\iwsh\\venv\\lib\\site-packages\\keras_tuner\\engine\\tuner.py:295\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[1;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[0;32m    293\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(model_checkpoint)\n\u001b[0;32m    294\u001b[0m     copied_kwargs[\u001b[39m\"\u001b[39m\u001b[39mcallbacks\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m callbacks\n\u001b[1;32m--> 295\u001b[0m     obj_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_and_fit_model(trial, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcopied_kwargs)\n\u001b[0;32m    297\u001b[0m     histories\u001b[39m.\u001b[39mappend(obj_value)\n\u001b[0;32m    298\u001b[0m \u001b[39mreturn\u001b[39;00m histories\n",
      "File \u001b[1;32mc:\\Users\\shubham\\Documents\\git\\iwsh\\venv\\lib\\site-packages\\keras_tuner\\engine\\tuner.py:222\u001b[0m, in \u001b[0;36mTuner._build_and_fit_model\u001b[1;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m hp \u001b[39m=\u001b[39m trial\u001b[39m.\u001b[39mhyperparameters\n\u001b[0;32m    221\u001b[0m model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_build(hp)\n\u001b[1;32m--> 222\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhypermodel\u001b[39m.\u001b[39mfit(hp, model, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    223\u001b[0m tuner_utils\u001b[39m.\u001b[39mvalidate_trial_results(\n\u001b[0;32m    224\u001b[0m     results, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mobjective, \u001b[39m\"\u001b[39m\u001b[39mHyperModel.fit()\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    225\u001b[0m )\n\u001b[0;32m    226\u001b[0m \u001b[39mreturn\u001b[39;00m results\n",
      "File \u001b[1;32mc:\\Users\\shubham\\Documents\\git\\iwsh\\venv\\lib\\site-packages\\keras_tuner\\engine\\hypermodel.py:140\u001b[0m, in \u001b[0;36mHyperModel.fit\u001b[1;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, hp, model, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    117\u001b[0m     \u001b[39m\"\"\"Train the model.\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \n\u001b[0;32m    119\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 140\u001b[0m     \u001b[39mreturn\u001b[39;00m model\u001b[39m.\u001b[39mfit(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\shubham\\Documents\\git\\iwsh\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\shubham\\Documents\\git\\iwsh\\venv\\lib\\site-packages\\keras\\engine\\training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1403\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1404\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1405\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1406\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1407\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1408\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1409\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1410\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1411\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\shubham\\Documents\\git\\iwsh\\venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\shubham\\Documents\\git\\iwsh\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\shubham\\Documents\\git\\iwsh\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\shubham\\Documents\\git\\iwsh\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2450\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m   2452\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\shubham\\Documents\\git\\iwsh\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1856\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1857\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1858\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1859\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1860\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1861\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1862\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m     args,\n\u001b[0;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1865\u001b[0m     executing_eagerly)\n\u001b[0;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\shubham\\Documents\\git\\iwsh\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    496\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    498\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    499\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    500\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    501\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    502\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    503\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    505\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    506\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    510\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\shubham\\Documents\\git\\iwsh\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tuner.search(X_train, y_train,\n",
    "             epochs=10,\n",
    "             validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in number\\number\n",
      "Showing 10 best trials\n",
      "<keras_tuner.engine.objective.Objective object at 0x000001EDFDE5FE80>\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 4\n",
      "units_0: 320\n",
      "units_1: 352\n",
      "learning_rate: 0.001\n",
      "units_2: 448\n",
      "units_3: 384\n",
      "units_4: 320\n",
      "units_5: 32\n",
      "units_6: 288\n",
      "units_7: 320\n",
      "units_8: 32\n",
      "units_9: 32\n",
      "units_10: 352\n",
      "units_11: 160\n",
      "units_12: 64\n",
      "units_13: 480\n",
      "units_14: 64\n",
      "units_15: 160\n",
      "units_16: 64\n",
      "units_17: 320\n",
      "units_18: 480\n",
      "Score: 0.9666666587193807\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 8\n",
      "units_0: 448\n",
      "units_1: 288\n",
      "learning_rate: 0.0001\n",
      "units_2: 512\n",
      "units_3: 96\n",
      "units_4: 64\n",
      "units_5: 512\n",
      "units_6: 288\n",
      "units_7: 288\n",
      "units_8: 416\n",
      "units_9: 352\n",
      "units_10: 224\n",
      "units_11: 480\n",
      "units_12: 352\n",
      "units_13: 320\n",
      "units_14: 512\n",
      "units_15: 64\n",
      "units_16: 192\n",
      "units_17: 64\n",
      "units_18: 160\n",
      "Score: 0.9638888835906982\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 2\n",
      "units_0: 128\n",
      "units_1: 448\n",
      "learning_rate: 0.001\n",
      "units_2: 224\n",
      "units_3: 224\n",
      "units_4: 160\n",
      "units_5: 512\n",
      "units_6: 480\n",
      "units_7: 512\n",
      "units_8: 96\n",
      "units_9: 160\n",
      "units_10: 512\n",
      "units_11: 448\n",
      "units_12: 32\n",
      "units_13: 448\n",
      "units_14: 224\n",
      "units_15: 384\n",
      "units_16: 160\n",
      "units_17: 160\n",
      "units_18: 352\n",
      "Score: 0.9629629453023275\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 10\n",
      "units_0: 160\n",
      "units_1: 352\n",
      "learning_rate: 0.001\n",
      "units_2: 320\n",
      "units_3: 448\n",
      "units_4: 384\n",
      "units_5: 192\n",
      "units_6: 224\n",
      "units_7: 384\n",
      "units_8: 192\n",
      "units_9: 224\n",
      "units_10: 96\n",
      "units_11: 352\n",
      "units_12: 480\n",
      "units_13: 192\n",
      "units_14: 480\n",
      "units_15: 288\n",
      "units_16: 320\n",
      "units_17: 224\n",
      "units_18: 256\n",
      "Score: 0.962499996026357\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 13\n",
      "units_0: 416\n",
      "units_1: 128\n",
      "learning_rate: 0.0001\n",
      "units_2: 224\n",
      "units_3: 416\n",
      "units_4: 128\n",
      "units_5: 64\n",
      "units_6: 448\n",
      "units_7: 256\n",
      "units_8: 256\n",
      "units_9: 384\n",
      "units_10: 224\n",
      "units_11: 448\n",
      "units_12: 416\n",
      "units_13: 384\n",
      "units_14: 320\n",
      "units_15: 448\n",
      "units_16: 64\n",
      "units_17: 96\n",
      "units_18: 160\n",
      "Score: 0.9620370268821716\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 6\n",
      "units_0: 32\n",
      "units_1: 32\n",
      "learning_rate: 0.001\n",
      "units_2: 416\n",
      "units_3: 128\n",
      "units_4: 96\n",
      "units_5: 224\n",
      "units_6: 480\n",
      "units_7: 64\n",
      "units_8: 480\n",
      "units_9: 480\n",
      "units_10: 288\n",
      "units_11: 480\n",
      "units_12: 192\n",
      "units_13: 352\n",
      "units_14: 192\n",
      "units_15: 320\n",
      "units_16: 32\n",
      "units_17: 320\n",
      "units_18: 352\n",
      "Score: 0.9615740776062012\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 14\n",
      "units_0: 128\n",
      "units_1: 480\n",
      "learning_rate: 0.0001\n",
      "units_2: 96\n",
      "units_3: 384\n",
      "units_4: 352\n",
      "units_5: 96\n",
      "units_6: 160\n",
      "units_7: 480\n",
      "units_8: 256\n",
      "units_9: 256\n",
      "units_10: 480\n",
      "units_11: 64\n",
      "units_12: 352\n",
      "units_13: 320\n",
      "units_14: 64\n",
      "units_15: 288\n",
      "units_16: 32\n",
      "units_17: 416\n",
      "units_18: 128\n",
      "Score: 0.9606481393178304\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 6\n",
      "units_0: 480\n",
      "units_1: 96\n",
      "learning_rate: 0.001\n",
      "units_2: 192\n",
      "units_3: 224\n",
      "units_4: 416\n",
      "units_5: 192\n",
      "units_6: 128\n",
      "units_7: 448\n",
      "units_8: 256\n",
      "units_9: 64\n",
      "units_10: 416\n",
      "units_11: 512\n",
      "units_12: 32\n",
      "units_13: 256\n",
      "units_14: 160\n",
      "units_15: 224\n",
      "units_16: 352\n",
      "units_17: 224\n",
      "units_18: 128\n",
      "Score: 0.96018519004186\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 10\n",
      "units_0: 288\n",
      "units_1: 448\n",
      "learning_rate: 0.0001\n",
      "units_2: 256\n",
      "units_3: 288\n",
      "units_4: 448\n",
      "units_5: 32\n",
      "units_6: 256\n",
      "units_7: 384\n",
      "units_8: 224\n",
      "units_9: 480\n",
      "units_10: 224\n",
      "units_11: 288\n",
      "units_12: 256\n",
      "units_13: 224\n",
      "units_14: 160\n",
      "units_15: 320\n",
      "units_16: 352\n",
      "units_17: 352\n",
      "units_18: 32\n",
      "Score: 0.9597222208976746\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 6\n",
      "units_0: 64\n",
      "units_1: 384\n",
      "learning_rate: 0.0001\n",
      "units_2: 256\n",
      "units_3: 416\n",
      "units_4: 480\n",
      "units_5: 480\n",
      "units_6: 224\n",
      "units_7: 416\n",
      "units_8: 128\n",
      "units_9: 128\n",
      "units_10: 128\n",
      "units_11: 480\n",
      "units_12: 64\n",
      "units_13: 64\n",
      "units_14: 448\n",
      "units_15: 256\n",
      "units_16: 416\n",
      "units_17: 224\n",
      "units_18: 352\n",
      "Score: 0.9597222010294596\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nTrial summary\\nHyperparameters:\\nnum_layers: 4\\nunits_0: 320\\nunits_1: 352\\nlearning_rate: 0.001\\nunits_2: 448\\nunits_3: 384\\nunits_4: 320\\nunits_5: 32\\nunits_6: 288\\nunits_7: 320\\nunits_8: 32\\nunits_9: 32\\nunits_10: 352\\nunits_11: 160\\nunits_12: 64\\nunits_13: 480\\nunits_14: 64\\nunits_15: 160\\nunits_16: 64\\nunits_17: 320\\nunits_18: 480\\nScore: 0.9666666587193807\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner.results_summary()\n",
    "\n",
    "'''\n",
    "Trial summary\n",
    "Hyperparameters:\n",
    "num_layers: 4\n",
    "units_0: 320\n",
    "units_1: 352\n",
    "learning_rate: 0.001\n",
    "units_2: 448\n",
    "units_3: 384\n",
    "units_4: 320\n",
    "units_5: 32\n",
    "units_6: 288\n",
    "units_7: 320\n",
    "units_8: 32\n",
    "units_9: 32\n",
    "units_10: 352\n",
    "units_11: 160\n",
    "units_12: 64\n",
    "units_13: 480\n",
    "units_14: 64\n",
    "units_15: 160\n",
    "units_16: 64\n",
    "units_17: 320\n",
    "units_18: 480\n",
    "Score: 0.9666666587193807\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras_tuner.engine.hyperparameters.HyperParameters at 0x1edfde8bfd0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "best_hps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.models.Sequential([\n",
    "#     tf.keras.layers.Input(((21 * 2) + 1, )),\n",
    "#     tf.keras.layers.Dropout(0.2),\n",
    "#     tf.keras.layers.Dense(256, activation=tf.nn.sigmoid),\n",
    "#     tf.keras.layers.Dropout(0.4),\n",
    "#     tf.keras.layers.Dense(128, activation='relu'),\n",
    "#     tf.keras.layers.Dropout(0.4),\n",
    "#     tf.keras.layers.Dense(64, activation='relu'),\n",
    "#     tf.keras.layers.Dropout(0.4),\n",
    "#     tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "# ])\n",
    "\n",
    "# # Model checkpoint callback\n",
    "# cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "#     model_save_path, verbose=1, save_weights_only=False)\n",
    "# # Callback for early stopping\n",
    "# es_callback = tf.keras.callbacks.EarlyStopping(patience=20, verbose=1)\n",
    "\n",
    "# model.compile(\n",
    "#     optimizer='adam',\n",
    "#     loss='sparse_categorical_crossentropy',\n",
    "#     metrics=['accuracy']\n",
    "# )\n",
    "\n",
    "# model.fit(\n",
    "#     X_train,\n",
    "#     y_train,\n",
    "#     epochs=1000,\n",
    "#     batch_size=128,\n",
    "#     validation_data=(X_test, y_test),\n",
    "# )\n",
    "\n",
    "# val_loss, val_acc = model.evaluate(X_test, y_test, batch_size=128)\n",
    "# print(val_loss, val_acc)\n",
    "\n",
    "# model = tf.keras.models.load_model(model_save_path)\n",
    "\n",
    "# predict_result = model.predict(np.array([X_test[10]]))\n",
    "# print(np.squeeze(predict_result))\n",
    "# print(np.argmax(np.squeeze(predict_result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "107/107 [==============================] - 2s 7ms/step - loss: 1.0588 - accuracy: 0.5960 - val_loss: 0.6481 - val_accuracy: 0.7389\n",
      "Epoch 2/100\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.4805 - accuracy: 0.8446 - val_loss: 0.3711 - val_accuracy: 0.8556\n",
      "Epoch 3/100\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.3058 - accuracy: 0.9084 - val_loss: 0.3014 - val_accuracy: 0.8917\n",
      "Epoch 4/100\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.2638 - accuracy: 0.9203 - val_loss: 0.2277 - val_accuracy: 0.9306\n",
      "Epoch 5/100\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 0.2294 - accuracy: 0.9273 - val_loss: 0.1697 - val_accuracy: 0.9472\n",
      "Epoch 6/100\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.2193 - accuracy: 0.9340 - val_loss: 0.2180 - val_accuracy: 0.9389\n",
      "Epoch 7/100\n",
      "107/107 [==============================] - 0s 5ms/step - loss: 0.1956 - accuracy: 0.9427 - val_loss: 0.1555 - val_accuracy: 0.9528\n",
      "Epoch 8/100\n",
      "107/107 [==============================] - 0s 5ms/step - loss: 0.1743 - accuracy: 0.9475 - val_loss: 0.1567 - val_accuracy: 0.9597\n",
      "Epoch 9/100\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 0.1731 - accuracy: 0.9484 - val_loss: 0.1696 - val_accuracy: 0.9403\n",
      "Epoch 10/100\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 0.1692 - accuracy: 0.9473 - val_loss: 0.1688 - val_accuracy: 0.9514\n",
      "Epoch 11/100\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 0.1447 - accuracy: 0.9570 - val_loss: 0.1766 - val_accuracy: 0.9444\n",
      "Epoch 12/100\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.1540 - accuracy: 0.9528 - val_loss: 0.1529 - val_accuracy: 0.9500\n",
      "Epoch 13/100\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.1243 - accuracy: 0.9627 - val_loss: 0.1363 - val_accuracy: 0.9625\n",
      "Epoch 14/100\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.1244 - accuracy: 0.9626 - val_loss: 0.1124 - val_accuracy: 0.9681\n",
      "Epoch 15/100\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 0.1316 - accuracy: 0.9595 - val_loss: 0.1830 - val_accuracy: 0.9403\n",
      "Epoch 16/100\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 0.1411 - accuracy: 0.9561 - val_loss: 0.0985 - val_accuracy: 0.9722\n",
      "Epoch 17/100\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 0.1313 - accuracy: 0.9610 - val_loss: 0.1296 - val_accuracy: 0.9611\n",
      "Epoch 18/100\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 0.1131 - accuracy: 0.9661 - val_loss: 0.1167 - val_accuracy: 0.9681\n",
      "Epoch 19/100\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 0.1045 - accuracy: 0.9688 - val_loss: 0.1255 - val_accuracy: 0.9611\n",
      "Epoch 20/100\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 0.1050 - accuracy: 0.9679 - val_loss: 0.0946 - val_accuracy: 0.9653\n",
      "Epoch 21/100\n",
      "107/107 [==============================] - 0s 5ms/step - loss: 0.1197 - accuracy: 0.9621 - val_loss: 0.1062 - val_accuracy: 0.9694\n",
      "Epoch 22/100\n",
      "107/107 [==============================] - 0s 5ms/step - loss: 0.1044 - accuracy: 0.9689 - val_loss: 0.0938 - val_accuracy: 0.9708\n",
      "Epoch 23/100\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.0982 - accuracy: 0.9699 - val_loss: 0.1028 - val_accuracy: 0.9694\n",
      "Epoch 24/100\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 0.1059 - accuracy: 0.9663 - val_loss: 0.1095 - val_accuracy: 0.9611\n",
      "Epoch 25/100\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 0.0918 - accuracy: 0.9727 - val_loss: 0.1090 - val_accuracy: 0.9694\n",
      "Epoch 26/100\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 0.1068 - accuracy: 0.9659 - val_loss: 0.0831 - val_accuracy: 0.9667\n",
      "Epoch 27/100\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 0.0955 - accuracy: 0.9693 - val_loss: 0.1039 - val_accuracy: 0.9694\n",
      "Epoch 28/100\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.0876 - accuracy: 0.9732 - val_loss: 0.0875 - val_accuracy: 0.9708\n",
      "Epoch 29/100\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.0823 - accuracy: 0.9744 - val_loss: 0.0912 - val_accuracy: 0.9694\n",
      "Epoch 30/100\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 0.0725 - accuracy: 0.9783 - val_loss: 0.0887 - val_accuracy: 0.9750\n",
      "Epoch 31/100\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 0.0781 - accuracy: 0.9768 - val_loss: 0.1517 - val_accuracy: 0.9611\n",
      "Epoch 32/100\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 0.0926 - accuracy: 0.9699 - val_loss: 0.1951 - val_accuracy: 0.9319\n",
      "Epoch 33/100\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 0.0826 - accuracy: 0.9737 - val_loss: 0.0710 - val_accuracy: 0.9792\n",
      "Epoch 34/100\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 0.0776 - accuracy: 0.9756 - val_loss: 0.0543 - val_accuracy: 0.9833\n",
      "Epoch 35/100\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 0.0706 - accuracy: 0.9770 - val_loss: 0.0688 - val_accuracy: 0.9778\n",
      "Epoch 36/100\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 0.0968 - accuracy: 0.9696 - val_loss: 0.1074 - val_accuracy: 0.9639\n",
      "Epoch 37/100\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 0.0793 - accuracy: 0.9745 - val_loss: 0.1064 - val_accuracy: 0.9708\n",
      "Epoch 38/100\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 0.0769 - accuracy: 0.9751 - val_loss: 0.0626 - val_accuracy: 0.9778\n",
      "Epoch 39/100\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 0.0708 - accuracy: 0.9779 - val_loss: 0.0600 - val_accuracy: 0.9736\n",
      "Epoch 40/100\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 0.0812 - accuracy: 0.9745 - val_loss: 0.0581 - val_accuracy: 0.9806\n",
      "Epoch 41/100\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 0.0757 - accuracy: 0.9751 - val_loss: 0.0587 - val_accuracy: 0.9792\n",
      "Epoch 42/100\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 0.0681 - accuracy: 0.9777 - val_loss: 0.0621 - val_accuracy: 0.9778\n",
      "Epoch 43/100\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 0.0765 - accuracy: 0.9753 - val_loss: 0.0609 - val_accuracy: 0.9792\n",
      "Epoch 44/100\n",
      "107/107 [==============================] - 0s 5ms/step - loss: 0.0525 - accuracy: 0.9832 - val_loss: 0.0373 - val_accuracy: 0.9861\n",
      "Epoch 45/100\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.0645 - accuracy: 0.9785 - val_loss: 0.0716 - val_accuracy: 0.9792\n",
      "Epoch 46/100\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.0707 - accuracy: 0.9778 - val_loss: 0.0650 - val_accuracy: 0.9708\n",
      "Epoch 47/100\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 0.0666 - accuracy: 0.9793 - val_loss: 0.0706 - val_accuracy: 0.9764\n",
      "Epoch 48/100\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 0.0506 - accuracy: 0.9838 - val_loss: 0.0736 - val_accuracy: 0.9764\n",
      "Epoch 49/100\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 0.0810 - accuracy: 0.9742 - val_loss: 0.0490 - val_accuracy: 0.9833\n",
      "Epoch 50/100\n",
      "107/107 [==============================] - 0s 5ms/step - loss: 0.0472 - accuracy: 0.9849 - val_loss: 0.0713 - val_accuracy: 0.9819\n",
      "Epoch 51/100\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.0536 - accuracy: 0.9827 - val_loss: 0.0485 - val_accuracy: 0.9847\n",
      "Epoch 52/100\n",
      "107/107 [==============================] - 0s 5ms/step - loss: 0.0547 - accuracy: 0.9819 - val_loss: 0.0502 - val_accuracy: 0.9806\n",
      "Epoch 53/100\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 0.0591 - accuracy: 0.9808 - val_loss: 0.0608 - val_accuracy: 0.9778\n",
      "Epoch 54/100\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 0.0582 - accuracy: 0.9800 - val_loss: 0.0766 - val_accuracy: 0.9806\n",
      "Epoch 55/100\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 0.0501 - accuracy: 0.9834 - val_loss: 0.0589 - val_accuracy: 0.9833\n",
      "Epoch 56/100\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 0.0570 - accuracy: 0.9816 - val_loss: 0.1597 - val_accuracy: 0.9472\n",
      "Epoch 57/100\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.0752 - accuracy: 0.9746 - val_loss: 0.0765 - val_accuracy: 0.9708\n",
      "Epoch 58/100\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.0616 - accuracy: 0.9803 - val_loss: 0.0521 - val_accuracy: 0.9889\n",
      "Epoch 59/100\n",
      "107/107 [==============================] - 0s 5ms/step - loss: 0.0509 - accuracy: 0.9827 - val_loss: 0.0584 - val_accuracy: 0.9792\n",
      "Epoch 60/100\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 0.0368 - accuracy: 0.9884 - val_loss: 0.0450 - val_accuracy: 0.9833\n",
      "Epoch 61/100\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 0.0523 - accuracy: 0.9835 - val_loss: 0.0683 - val_accuracy: 0.9792\n",
      "Epoch 62/100\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 0.0578 - accuracy: 0.9800 - val_loss: 0.0475 - val_accuracy: 0.9847\n",
      "Epoch 63/100\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 0.0427 - accuracy: 0.9857 - val_loss: 0.0521 - val_accuracy: 0.9792\n",
      "Epoch 64/100\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.0545 - accuracy: 0.9813 - val_loss: 0.1572 - val_accuracy: 0.9444\n",
      "Epoch 65/100\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.0599 - accuracy: 0.9797 - val_loss: 0.0543 - val_accuracy: 0.9861\n",
      "Epoch 66/100\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.0360 - accuracy: 0.9890 - val_loss: 0.0396 - val_accuracy: 0.9889\n",
      "Epoch 67/100\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.0401 - accuracy: 0.9873 - val_loss: 0.0467 - val_accuracy: 0.9806\n",
      "Epoch 68/100\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.0353 - accuracy: 0.9887 - val_loss: 0.0478 - val_accuracy: 0.9833\n",
      "Epoch 69/100\n",
      "107/107 [==============================] - 0s 5ms/step - loss: 0.0485 - accuracy: 0.9842 - val_loss: 0.0568 - val_accuracy: 0.9778\n",
      "Epoch 70/100\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 0.0393 - accuracy: 0.9860 - val_loss: 0.0517 - val_accuracy: 0.9889\n",
      "Epoch 71/100\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 0.0501 - accuracy: 0.9837 - val_loss: 0.0518 - val_accuracy: 0.9833\n",
      "Epoch 72/100\n",
      "107/107 [==============================] - 0s 5ms/step - loss: 0.0486 - accuracy: 0.9831 - val_loss: 0.0473 - val_accuracy: 0.9875\n",
      "Epoch 73/100\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.0474 - accuracy: 0.9837 - val_loss: 0.0674 - val_accuracy: 0.9819\n",
      "Epoch 74/100\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.0502 - accuracy: 0.9831 - val_loss: 0.0403 - val_accuracy: 0.9833\n",
      "Epoch 75/100\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 0.0374 - accuracy: 0.9870 - val_loss: 0.0504 - val_accuracy: 0.9833\n",
      "Epoch 76/100\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 0.0364 - accuracy: 0.9871 - val_loss: 0.0285 - val_accuracy: 0.9903\n",
      "Epoch 77/100\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.0299 - accuracy: 0.9898 - val_loss: 0.0434 - val_accuracy: 0.9889\n",
      "Epoch 78/100\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.0448 - accuracy: 0.9856 - val_loss: 0.0536 - val_accuracy: 0.9806\n",
      "Epoch 79/100\n",
      "107/107 [==============================] - 0s 5ms/step - loss: 0.0448 - accuracy: 0.9856 - val_loss: 0.0360 - val_accuracy: 0.9847\n",
      "Epoch 80/100\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 0.0490 - accuracy: 0.9841 - val_loss: 0.1813 - val_accuracy: 0.9431\n",
      "Epoch 81/100\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 0.0517 - accuracy: 0.9831 - val_loss: 0.0475 - val_accuracy: 0.9792\n",
      "Epoch 82/100\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 0.0196 - accuracy: 0.9933 - val_loss: 0.0402 - val_accuracy: 0.9861\n",
      "Epoch 83/100\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.0360 - accuracy: 0.9884 - val_loss: 0.0322 - val_accuracy: 0.9875\n",
      "Epoch 84/100\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.0255 - accuracy: 0.9916 - val_loss: 0.0359 - val_accuracy: 0.9889\n",
      "Epoch 85/100\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.0317 - accuracy: 0.9882 - val_loss: 0.0252 - val_accuracy: 0.9903\n",
      "Epoch 86/100\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 0.0411 - accuracy: 0.9860 - val_loss: 0.0477 - val_accuracy: 0.9833\n",
      "Epoch 87/100\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 0.0304 - accuracy: 0.9892 - val_loss: 0.0221 - val_accuracy: 0.9958\n",
      "Epoch 88/100\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 0.0223 - accuracy: 0.9928 - val_loss: 0.0344 - val_accuracy: 0.9889\n",
      "Epoch 89/100\n",
      "107/107 [==============================] - 0s 5ms/step - loss: 0.0432 - accuracy: 0.9860 - val_loss: 0.0461 - val_accuracy: 0.9833\n",
      "Epoch 90/100\n",
      "107/107 [==============================] - 0s 5ms/step - loss: 0.0254 - accuracy: 0.9924 - val_loss: 0.0300 - val_accuracy: 0.9917\n",
      "Epoch 91/100\n",
      "107/107 [==============================] - 0s 5ms/step - loss: 0.0244 - accuracy: 0.9910 - val_loss: 0.0505 - val_accuracy: 0.9875\n",
      "Epoch 92/100\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 0.0336 - accuracy: 0.9876 - val_loss: 0.0567 - val_accuracy: 0.9806\n",
      "Epoch 93/100\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 0.0420 - accuracy: 0.9868 - val_loss: 0.0612 - val_accuracy: 0.9833\n",
      "Epoch 94/100\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 0.0414 - accuracy: 0.9866 - val_loss: 0.0607 - val_accuracy: 0.9792\n",
      "Epoch 95/100\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.0400 - accuracy: 0.9867 - val_loss: 0.0644 - val_accuracy: 0.9778\n",
      "Epoch 96/100\n",
      "107/107 [==============================] - 0s 5ms/step - loss: 0.0300 - accuracy: 0.9900 - val_loss: 0.0535 - val_accuracy: 0.9903\n",
      "Epoch 97/100\n",
      "107/107 [==============================] - 0s 5ms/step - loss: 0.0304 - accuracy: 0.9898 - val_loss: 0.0734 - val_accuracy: 0.9778\n",
      "Epoch 98/100\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 0.0375 - accuracy: 0.9876 - val_loss: 0.0575 - val_accuracy: 0.9792\n",
      "Epoch 99/100\n",
      "107/107 [==============================] - 1s 6ms/step - loss: 0.0312 - accuracy: 0.9887 - val_loss: 0.0447 - val_accuracy: 0.9889\n",
      "Epoch 100/100\n",
      "107/107 [==============================] - 1s 5ms/step - loss: 0.0324 - accuracy: 0.9891 - val_loss: 0.0365 - val_accuracy: 0.9861\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    batch_size=128,\n",
    "    validation_data=(X_test, y_test),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0365 - accuracy: 0.9861\n",
      "0.03650173172354698 0.9861111044883728\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = model.evaluate(X_test, y_test, batch_size=128)\n",
    "print(val_loss, val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step\n",
      "[1.2022798e-05 2.1335177e-08 5.2354102e-07 9.9995410e-01 3.3361008e-05\n",
      " 4.1410253e-09]\n",
      "3\n",
      "[3]\n"
     ]
    }
   ],
   "source": [
    "observation = 100\n",
    "\n",
    "predict_result = model.predict(np.array([X_test[observation]]))\n",
    "print(np.squeeze(predict_result))\n",
    "print(np.argmax(np.squeeze(predict_result)))\n",
    "print(np.array([y_test[observation]]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "33a4c9a236d90520a0c46e4f630334a9a04ccfacca16be9bf57c93a35c2551c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
